{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal language model POCs and OpenAI API demo\n",
    "\n",
    "Prepared for Ventera brownbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tiktoken\n",
    "from utilities import GPT_utilities\n",
    "\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "gptkey = GPT_utilities()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General example to highlight factual accuracy and confabulation i.e. 'truthiness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The 100 meter dash at the 2020 Olympics was won by Jamaica's Shelly-Ann Fraser-Pryce.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"who won the 100 meter dash 2020 olympics?\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Noble Ackerson is the creator of LynxFit, a fitness and lifestyle brand that focuses on helping people reach their health and fitness goals. He is a certified personal trainer, nutritionist, and lifestyle coach. He has been featured in publications such as Men's Health, Men's Fitness, and Muscle & Fitness. He has also been featured on the cover of Muscle & Fitness magazine. He has a passion for helping people reach their goals and believes that everyone should have access to the best fitness and nutrition information. He is also the founder of the LynxFit Academy, an online fitness and nutrition education platform.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"tell me about Noble Ackerson the LynxFit creator\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sorry, I don't know.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\".\n",
    "\n",
    "Q: How many sprints in a PI?\n",
    "A:\"\"\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Engineering approach to mitigate accuracy and confabulation i.e. 'truthiness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible using the provided text, and if the answer is not contained within the text below, say \"I don't know\"\n",
    "\n",
    "Context:\n",
    "A Minimum Viable Product (MVP) is a version of a working product that allows the team to learn from and \n",
    "interact with their customer with the least amount of effort. MVP attends to the core customer needs \n",
    "first and as soon as possible. It helps to validate needs, reduce risk, and help the programs course correct \n",
    "quickly, as needed. Rooted in concepts that emerged from the book “The Lean Startup” by Eric Ries, the core \n",
    "idea is to facilitate a better understanding of the customers needs and interests without committing or \n",
    "using a large number of resources or fully developing a product.\n",
    "\n",
    "Q: What's the main idea behind MVP?\n",
    "A:\"\"\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible using the provided text, and if the answer is not contained within the text below, say \"I don't know\"\n",
    "\n",
    "Context:\n",
    "In the NFC final, the Eagles defeated the San Francisco 49ers in a 31-7 blowout. \n",
    "This will be the fourth Super Bowl appearance for the Eagles, who lost in 1980 to the Oakland Raiders and in 2004 to the New England Patriots. \n",
    "In their most recent appearance in 2017, they got their revenge with a victory over the Patriots. \n",
    "Quarterback Jalen Hurts is in just his second season as a starter for the Eagles, \n",
    "taking them to the playoffs both years.\n",
    "\n",
    "Q: How many times have the Eagles beaten the Patriots in a superbowl?\n",
    "A:\"\"\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetune Model approach to increase trustworthiness by example: preprocessing data from vstart.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('vstart.csv')\n",
    "df = df.set_index([\"vscontent\"])\n",
    "print(f\"{len(df)} rows in the data.\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model: str = EMBEDDING_MODEL) -> list[float]:\n",
    "    \"\"\"\n",
    "    Use the OpenAI Embeddings API to create an embedding for the given text.\n",
    "    \"\"\"\n",
    "    result = openai.Embedding.create(model=model, input=text)\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> dict[str, list[float]]:\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "\n",
    "    Return a dictionary that maps between each embedding vector and the vscontent value of the row it corresponds to.\n",
    "    \"\"\"\n",
    "    return {r['vscontent']: get_embedding(r['vscontent']) for idx, r in df.iterrows()}\n",
    "\n",
    "def load_embeddings(fname: str) -> dict[str, list[float]]:\n",
    "    \"\"\"\n",
    "    Read the document embeddings from a CSV.\n",
    "\n",
    "    fname is the path to a CSV with exactly these named columns: \n",
    "        \"vscontent\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(fname, header=0)\n",
    "    max_dim = max([int(c) for c in df.columns if c != \"vscontent\"])\n",
    "    return {r[0]: [r[i] for i in range(1, max_dim + 1)] for r in df.itertuples(index=False)}\n",
    "\n",
    "df = pd.read_csv(\"vstart.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = compute_doc_embeddings(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets save our embeddings in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(embeddings: dict[str, list[float]], fname: str):\n",
    "    df = pd.DataFrame.from_dict(embeddings, orient='index')\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'vscontent'}, inplace=True)\n",
    "    df.to_csv(fname, index=False)\n",
    "\n",
    "\n",
    "output_folder = \"output\"\n",
    "output_fname = f\"{output_folder}/embeddings.csv\"\n",
    "save_embeddings(document_embeddings, output_fname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets view what an embedding looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_text = list(document_embeddings.keys())[0]\n",
    "first_embedding = list(document_embeddings.values())[0]\n",
    "truncated_text = first_text[:50] + \"...\"\n",
    "print(\"Example:\", truncated_text, first_embedding[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Semantic Search use case\n",
    "\n",
    "...by finding the most similar document embeddings to the question embedding. We're storing this locally but for a larger dataset we would consider a vector DB to index our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(x: list[float], y: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    Returns the similarity between two vectors.\n",
    "    \n",
    "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))\n",
    "\n",
    "def order_document_sections_by_query_similarity(query: str, contexts: dict[(str, str), np.array]) -> list[(float, (str, str))]:\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "    \n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "    \n",
    "    return document_similarities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets try a semantic search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.799902303463576,\n",
       "  \"In SAFe (Scaled Agile Framework)a Program Increment (PI) typically lasts for 8 to 12 weeks and is divided into sprints. The number of sprints in a PI depends on the length of the sprint cycle that the organization has chosen.If you're not using the Scaled Agile Framework (SAFe) you can still follow the principles of Agile development and use sprints to show progress. Here are the steps to breakup your sprints.Determine the length of your sprint cycle: The length of your sprint cycle will depend on the size of your team and the complexity of your project. A common sprint cycle length is 2-4 weeks.Identify your sprint backlog: This is a prioritized list of tasks that your team will work on during the sprint. The sprint backlog should be updated regularly to reflect changes in the project requirements and priorities.Plan your sprint: During the sprint planning meeting your team will review the sprint backlog and determine which tasks they can complete during the sprint. They will also create a detailed plan of how they will complete each task.\"),\n",
       " (0.751582309035703,\n",
       "  'Sprint zero is the initial sprint for a project that focuses on activities to help the team prepare for the upcoming sprint cadence.'),\n",
       " (0.7288726173489952,\n",
       "  \"A Sprint Retrospective is a scrum team ceremony that occurs after the Sprint Review and before the next Sprint Planning. It is an opportunity for the Scrum Team to openly discuss what went well and what didn't in the previous sprint. The outcome is to create a plan for necessary actions and improvements to be enacted and during the next sprint.\"),\n",
       " (0.7019458552481562,\n",
       "  'Product backlog refinement (PFR) is a continuous review of the product backlog (dynamic body of information) to create a shared understanding of the functionality to be developed. This ensures that the top priority items in the backlog are ready for development in the next sprints.'),\n",
       " (0.6950508171867026,\n",
       "  'User stories are small, tangible requirements that can be used to communicate and summarize the functionality of the product. They contain a list of acceptance criteria that determine when the user story can be considered done. Larger user stories will be classified as Features and then Epics. Both will later be decomposed to fit into a single sprint.')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_document_sections_by_query_similarity(\"how many sprints in a PI\", document_embeddings)[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
